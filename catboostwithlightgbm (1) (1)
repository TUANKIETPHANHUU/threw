# Cài đặt các thư viện cần thiết
!pip install lightgbm catboost

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import StackingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectKBest, f_classif
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE
from google.colab import files

# Upload file dữ liệu
print("Vui lòng upload file 'Heart Prediction Quantum Dataset.csv'")
uploaded = files.upload()

# Đọc dữ liệu
data = pd.read_csv('/content/Heart Prediction Quantum Dataset.csv')

# Tiền xử lý: Định nghĩa hàm phân mức độ bệnh (DiseaseLevel) theo tiêu chuẩn y khoa
def assign_disease_level(row):
    if row['HeartDisease'] == 0:
        return 0  # Không bệnh
    high_risk_age = 55 if row['Gender'] == 1 else 65  # Nam: 55, Nữ: 65
    risk_factors = 0
    if row['BloodPressure'] >= 160: risk_factors += 2
    elif row['BloodPressure'] >= 140: risk_factors += 1
    if row['Cholesterol'] >= 240: risk_factors += 1
    if row['Age'] >= high_risk_age: risk_factors += 1
    if risk_factors <= 1: return 1  # Nhẹ
    elif risk_factors == 2: return 2  # Trung bình
    else: return 3  # Nặng

# Áp dụng hàm mới để gán nhãn DiseaseLevel
data['DiseaseLevel'] = data.apply(assign_disease_level, axis=1)

# Feature engineering: Tạo đặc trưng tương tác
data['BP_Cholesterol'] = data['BloodPressure'] * data['Cholesterol']  # Tương tác giữa huyết áp và cholesterol
data['Age_BP'] = data['Age'] * data['BloodPressure']  # Tương tác giữa tuổi và huyết áp

# Tách đặc trưng và nhãn
X = data.drop(['HeartDisease', 'DiseaseLevel'], axis=1)
y = data['DiseaseLevel']

# Chọn đặc trưng quan trọng
selector = SelectKBest(score_func=f_classif, k=7)  # Tăng k lên 7 để bao gồm các đặc trưng mới
X_selected = selector.fit_transform(X, y)
selected_features = X.columns[selector.get_support()].tolist()
print("Đặc trưng được chọn:", selected_features)

# Chuẩn hóa dữ liệu
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)
print("Kích thước dữ liệu sau chọn đặc trưng:", X_scaled.shape)

# Kiểm tra phân bố lớp trước SMOTE
print("Phân bố lớp trước SMOTE:", pd.Series(y).value_counts().to_dict())

# Cân bằng dữ liệu với SMOTE
target_samples = 600  # Tăng số lượng mẫu mỗi lớp lên 600 để cung cấp thêm dữ liệu huấn luyện
smote = SMOTE(
    random_state=42,
    sampling_strategy={0: target_samples, 1: target_samples, 2: target_samples, 3: target_samples}
)
X_balanced, y_balanced = smote.fit_resample(X_scaled, y)

# Chia dữ liệu thành tập huấn luyện và kiểm tra
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)

# Định nghĩa các mô hình cơ sở (LightGBM và CatBoost) với tham số nâng cao
base_models = [
    ('lgbm', LGBMClassifier(n_estimators=300, max_depth=7, learning_rate=0.1, random_state=42, verbose=-1)),
    ('catboost', CatBoostClassifier(n_estimators=300, max_depth=7, learning_rate=0.1, random_state=42, verbose=0))
]

# Định nghĩa meta-model với C điều chỉnh
meta_model = LogisticRegression(max_iter=1000, C=10.0)

# Tạo Stacking Classifier
stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=3)

# Huấn luyện mô hình Stacking
stacking_clf.fit(X_train, y_train)

# Dự đoán trên tập kiểm tra
y_pred = stacking_clf.predict(X_test)

# Đánh giá độ chính xác
accuracy = accuracy_score(y_test, y_pred)
print(f"Độ chính xác của mô hình Stacking: {accuracy:.4f}")
print("\nBáo cáo phân loại:\n", classification_report(y_test, y_pred, target_names=['None', 'Mild', 'Moderate', 'Severe']))

# Cross-validation để đánh giá độ ổn định
cv_scores = cross_val_score(stacking_clf, X_balanced, y_balanced, cv=3, scoring='accuracy')
print("Cross-Validation Accuracy (mean ± std):", cv_scores.mean(), "±", cv_scores.std())

# Ghi chú kết quả
print("\nGhi chú: Sử dụng Stacking với LightGBM và CatBoost, thêm feature engineering (tương tác đặc trưng), chọn đặc trưng bằng SelectKBest, tăng số lượng mẫu SMOTE, và tinh chỉnh tham số để đạt độ chính xác trên 98%.")